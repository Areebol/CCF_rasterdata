{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从csv文件中转化为易读的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_file = \"../val_data/edge_test_4_A.csv\"\n",
    "node_file = \"../val_data/node_test_4_A.csv\"\n",
    "graph_id_file = \"../val_data/graph_id_map.pkl\"\n",
    "node_id_file = \"../val_data/node_id_maps.pkl\"\n",
    "graph_propertity_file = \"../val_data/graph_propertity.csv\"\n",
    "output_node_file=\"../val_data/nodes.csv\"\n",
    "output_edge_file=\"../val_data/edges.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 获取graph_id的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, save_file):\n",
    "    \"\"\"保存数据\"\"\"\n",
    "    import pickle\n",
    "    # 保存到文件\n",
    "    with open(save_file, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "\n",
    "def load_data(load_file):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    import pickle\n",
    "    # 打开文件\n",
    "    with open(load_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of graphs  4\n",
      "Graph mapping:  {20230404: 0, 20230405: 1, 20230406: 2, 20230407: 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nodes_df = pd.read_csv(node_file)  \n",
    "# 按照日期升序排列\n",
    "nodes_df = nodes_df.sort_values(by=['date_id'],ascending=[True])\n",
    "# 按照日期成组\n",
    "graph_nodes_dfs = nodes_df.groupby(by=\"date_id\")\n",
    "# date_id -> graph_id\n",
    "graph_id_map = {}\n",
    "for graph_id,graph_nodes_df in enumerate(graph_nodes_dfs):\n",
    "    graph_id_map[graph_nodes_df[0]] = graph_id\n",
    "graph_id_map_file = graph_id_file\n",
    "# 保存图序号映射\n",
    "save_data(graph_id_map,graph_id_map_file)\n",
    "# Info\n",
    "print(\"Size of graphs \",len(graph_nodes_dfs))\n",
    "print(\"Graph mapping: \",graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 获取node数据每个图的结点映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取单个图的结点映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_graph_node_map(graph_df):\n",
    "    \"\"\"传入graph的df数据 返回结点映射\"\"\"\n",
    "    # geohash_id -> node_id\n",
    "    node_id_map = {}\n",
    "    for node_id,(_, node_row) in enumerate(graph_df.iterrows()):\n",
    "        geohash_id = node_row[\"geohash_id\"]\n",
    "        node_id_map[geohash_id] = node_id\n",
    "    return node_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取全部图的结点映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_maps = []\n",
    "for graph_id,graph_nodes_df in enumerate(graph_nodes_dfs):\n",
    "    node_id_map = get_single_graph_node_map(graph_nodes_df[1])\n",
    "    node_id_maps.append(node_id_map)\n",
    "save_data(node_id_maps,node_id_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 获取edge数据的每个图的结点映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依据图序号对数据分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of graphs  4\n",
      "Graph mapping:  {20230404: 0, 20230405: 1, 20230406: 2, 20230407: 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "edges_df = pd.read_csv(edge_file)  \n",
    "# 按照日期升序排列\n",
    "edges_df = edges_df.sort_values(by=['date_id'],ascending=[True])\n",
    "# 按照日期成组\n",
    "graph_edges_dfs = edges_df.groupby(by=\"date_id\")\n",
    "# Info\n",
    "print(\"Size of graphs \",len(graph_nodes_dfs))\n",
    "print(\"Graph mapping: \",graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依据src，dst补充结点映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_single_graph_node_map(graph_df, node_id_map):\n",
    "    \"\"\"传入graph的edges数据 添加结点映射\"\"\"\n",
    "    node_id = len(node_id_map)\n",
    "    # geohash_id -> node_id\n",
    "    for _, node_row in graph_df.iterrows():\n",
    "        geohash_id1 = node_row[\"geohash6_point1\"]\n",
    "        geohash_id2 = node_row[\"geohash6_point2\"]\n",
    "        if geohash_id1 not in node_id_map:\n",
    "            node_id_map[geohash_id1] = node_id\n",
    "            node_id += 1\n",
    "            \n",
    "        if geohash_id2 not in node_id_map:\n",
    "            node_id_map[geohash_id2] = node_id\n",
    "            node_id += 1\n",
    "    return node_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1154, 1155}\n"
     ]
    }
   ],
   "source": [
    "# 按照日期升序排列\n",
    "edges_df = edges_df.sort_values(by=['date_id'],ascending=[True])\n",
    "node_id_maps=load_data(node_id_file)\n",
    "# 按照日期成组\n",
    "graph_edges_dfs = edges_df.groupby(by=\"date_id\")\n",
    "for graph_id,graph_edges_df in enumerate(graph_edges_dfs):\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    node_id_maps[graph_id] = add_single_graph_node_map(graph_edges_df[1],node_id_map)\n",
    "node_nums = set()\n",
    "for node_id_map in node_id_maps:\n",
    "    node_nums.add(len(node_id_map))\n",
    "print(node_nums)\n",
    "save_data(node_id_maps,node_id_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 获取每个图的结点数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_num_nodes(output_file,node_id_maps):\n",
    "    graphs_row = []\n",
    "    for graph_id, node_id_map in enumerate(node_id_maps):\n",
    "        print(f\"graph {graph_id} num_nodes is {len(node_id_map)}\")\n",
    "        graph_row = [graph_id,len(node_id_map)]\n",
    "        graphs_row.append(graph_row)\n",
    "    df = pd.DataFrame(graphs_row,columns=['graph_id','num_nodes']) \n",
    "    df.to_csv(output_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph 0 num_nodes is 1154\n",
      "graph 1 num_nodes is 1154\n",
      "graph 2 num_nodes is 1154\n",
      "graph 3 num_nodes is 1155\n"
     ]
    }
   ],
   "source": [
    "save_graph_num_nodes(graph_propertity_file,node_id_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 新增src,dst,graph_id,node_id列数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增graph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df['graph_id'] = nodes_df['date_id'].map(graph_id_map)\n",
    "edges_df['graph_id'] = edges_df['date_id'].map(graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "3788       1\n",
      "1404       2\n",
      "3084       3\n",
      "1400       4\n",
      "        ... \n",
      "2411    1135\n",
      "2407    1136\n",
      "2403    1137\n",
      "2395    1138\n",
      "4559    1139\n",
      "Name: node_id, Length: 4560, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 需要依据graph_id 分组映射\n",
    "node_id_maps=load_data(node_id_file)\n",
    "\n",
    "nodes_groupby_graph_id_df = nodes_df.groupby(by=\"graph_id\")\n",
    "result = []\n",
    "for graph_id,nodes_groupby_df in nodes_groupby_graph_id_df:\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    nodes_groupby_df['node_id'] = nodes_groupby_df['geohash_id'].map(node_id_map)\n",
    "    result.append(nodes_groupby_df)\n",
    "result = pd.concat(result)\n",
    "print(result[\"node_id\"])\n",
    "result.to_csv(output_node_file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增src，dst的node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42801     984\n",
      "51790     751\n",
      "51792     128\n",
      "51793     742\n",
      "51796     642\n",
      "         ... \n",
      "18316     770\n",
      "18311     588\n",
      "84441     680\n",
      "52534    1062\n",
      "73466     796\n",
      "Name: src, Length: 85604, dtype: int64"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "42801    548\n",
      "51790    614\n",
      "51792    886\n",
      "51793     90\n",
      "51796    748\n",
      "        ... \n",
      "18316    831\n",
      "18311    328\n",
      "84441    879\n",
      "52534    896\n",
      "73466    158\n",
      "Name: dst, Length: 85604, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "edges_groupby_graph_id_df = edges_df.groupby(by=\"graph_id\")\n",
    "result = []\n",
    "for graph_id,edges_groupby_df in edges_groupby_graph_id_df:\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    edges_groupby_df['src'] = edges_groupby_df['geohash6_point1'].map(node_id_map)\n",
    "    edges_groupby_df['dst'] = edges_groupby_df['geohash6_point2'].map(node_id_map)\n",
    "    result.append(edges_groupby_df)\n",
    "result = pd.concat(result)\n",
    "print(result[\"src\"])\n",
    "print(result[\"dst\"])\n",
    "result.to_csv(output_edge_file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
