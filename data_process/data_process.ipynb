{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从csv文件中转化为易读的数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_file = \"../data/edge_90.csv\"\n",
    "node_file = \"../data/train_90.csv\"\n",
    "graph_id_file = \"../data/graph_id_map.pkl\"\n",
    "node_id_file = \"../data/node_id_maps.pkl\"\n",
    "graph_propertity_file = \"../data/graph_propertity.csv\"\n",
    "output_node_file=\"../data/nodes.csv\"\n",
    "output_edge_file=\"../data/edges.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 获取graph_id的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, save_file):\n",
    "    \"\"\"保存数据\"\"\"\n",
    "    import pickle\n",
    "    # 保存到文件\n",
    "    with open(save_file, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "\n",
    "def load_data(load_file):\n",
    "    \"\"\"读取数据\"\"\"\n",
    "    import pickle\n",
    "    # 打开文件\n",
    "    with open(load_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of graphs  90\n",
      "Graph mapping:  {20230104: 0, 20230105: 1, 20230106: 2, 20230107: 3, 20230108: 4, 20230109: 5, 20230110: 6, 20230111: 7, 20230112: 8, 20230113: 9, 20230114: 10, 20230115: 11, 20230116: 12, 20230117: 13, 20230118: 14, 20230119: 15, 20230120: 16, 20230121: 17, 20230122: 18, 20230123: 19, 20230124: 20, 20230125: 21, 20230126: 22, 20230127: 23, 20230128: 24, 20230129: 25, 20230130: 26, 20230131: 27, 20230201: 28, 20230202: 29, 20230203: 30, 20230204: 31, 20230205: 32, 20230206: 33, 20230207: 34, 20230208: 35, 20230209: 36, 20230210: 37, 20230211: 38, 20230212: 39, 20230213: 40, 20230214: 41, 20230215: 42, 20230216: 43, 20230217: 44, 20230218: 45, 20230219: 46, 20230220: 47, 20230221: 48, 20230222: 49, 20230223: 50, 20230224: 51, 20230225: 52, 20230226: 53, 20230227: 54, 20230228: 55, 20230301: 56, 20230302: 57, 20230303: 58, 20230304: 59, 20230305: 60, 20230306: 61, 20230307: 62, 20230308: 63, 20230309: 64, 20230310: 65, 20230311: 66, 20230312: 67, 20230313: 68, 20230314: 69, 20230315: 70, 20230316: 71, 20230317: 72, 20230318: 73, 20230319: 74, 20230320: 75, 20230321: 76, 20230322: 77, 20230323: 78, 20230324: 79, 20230325: 80, 20230326: 81, 20230327: 82, 20230328: 83, 20230329: 84, 20230330: 85, 20230331: 86, 20230401: 87, 20230402: 88, 20230403: 89}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nodes_df = pd.read_csv(node_file)  \n",
    "# 按照日期升序排列\n",
    "nodes_df = nodes_df.sort_values(by=['date_id'],ascending=[True])\n",
    "# 按照日期成组\n",
    "graph_nodes_dfs = nodes_df.groupby(by=\"date_id\")\n",
    "# date_id -> graph_id\n",
    "graph_id_map = {}\n",
    "for graph_id,graph_nodes_df in enumerate(graph_nodes_dfs):\n",
    "    graph_id_map[graph_nodes_df[0]] = graph_id\n",
    "graph_id_map_file = graph_id_file\n",
    "# 保存图序号映射\n",
    "save_data(graph_id_map,graph_id_map_file)\n",
    "# Info\n",
    "print(\"Size of graphs \",len(graph_nodes_dfs))\n",
    "print(\"Graph mapping: \",graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 获取node数据每个图的结点映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取单个图的结点映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_graph_node_map(graph_df):\n",
    "    \"\"\"传入graph的df数据 返回结点映射\"\"\"\n",
    "    # geohash_id -> node_id\n",
    "    node_id_map = {}\n",
    "    for node_id,(_, node_row) in enumerate(graph_df.iterrows()):\n",
    "        geohash_id = node_row[\"geohash_id\"]\n",
    "        node_id_map[geohash_id] = node_id\n",
    "    return node_id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取全部图的结点映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_maps = []\n",
    "for graph_id,graph_nodes_df in enumerate(graph_nodes_dfs):\n",
    "    node_id_map = get_single_graph_node_map(graph_nodes_df[1])\n",
    "    node_id_maps.append(node_id_map)\n",
    "save_data(node_id_maps,node_id_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 获取edge数据的每个图的结点映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依据图序号对数据分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of graphs  90\n",
      "Graph mapping:  {20230104: 0, 20230105: 1, 20230106: 2, 20230107: 3, 20230108: 4, 20230109: 5, 20230110: 6, 20230111: 7, 20230112: 8, 20230113: 9, 20230114: 10, 20230115: 11, 20230116: 12, 20230117: 13, 20230118: 14, 20230119: 15, 20230120: 16, 20230121: 17, 20230122: 18, 20230123: 19, 20230124: 20, 20230125: 21, 20230126: 22, 20230127: 23, 20230128: 24, 20230129: 25, 20230130: 26, 20230131: 27, 20230201: 28, 20230202: 29, 20230203: 30, 20230204: 31, 20230205: 32, 20230206: 33, 20230207: 34, 20230208: 35, 20230209: 36, 20230210: 37, 20230211: 38, 20230212: 39, 20230213: 40, 20230214: 41, 20230215: 42, 20230216: 43, 20230217: 44, 20230218: 45, 20230219: 46, 20230220: 47, 20230221: 48, 20230222: 49, 20230223: 50, 20230224: 51, 20230225: 52, 20230226: 53, 20230227: 54, 20230228: 55, 20230301: 56, 20230302: 57, 20230303: 58, 20230304: 59, 20230305: 60, 20230306: 61, 20230307: 62, 20230308: 63, 20230309: 64, 20230310: 65, 20230311: 66, 20230312: 67, 20230313: 68, 20230314: 69, 20230315: 70, 20230316: 71, 20230317: 72, 20230318: 73, 20230319: 74, 20230320: 75, 20230321: 76, 20230322: 77, 20230323: 78, 20230324: 79, 20230325: 80, 20230326: 81, 20230327: 82, 20230328: 83, 20230329: 84, 20230330: 85, 20230331: 86, 20230401: 87, 20230402: 88, 20230403: 89}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "edges_df = pd.read_csv(edge_file)  \n",
    "# 按照日期升序排列\n",
    "edges_df = edges_df.sort_values(by=['date_id'],ascending=[True])\n",
    "# 按照日期成组\n",
    "graph_edges_dfs = edges_df.groupby(by=\"date_id\")\n",
    "# Info\n",
    "print(\"Size of graphs \",len(graph_nodes_dfs))\n",
    "print(\"Graph mapping: \",graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依据src，dst补充结点映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_single_graph_node_map(graph_df, node_id_map):\n",
    "    \"\"\"传入graph的edges数据 添加结点映射\"\"\"\n",
    "    node_id = len(node_id_map)\n",
    "    # geohash_id -> node_id\n",
    "    for _, node_row in graph_df.iterrows():\n",
    "        geohash_id1 = node_row[\"geohash6_point1\"]\n",
    "        geohash_id2 = node_row[\"geohash6_point2\"]\n",
    "        if geohash_id1 not in node_id_map:\n",
    "            node_id_map[geohash_id1] = node_id\n",
    "            node_id += 1\n",
    "            \n",
    "        if geohash_id2 not in node_id_map:\n",
    "            node_id_map[geohash_id2] = node_id\n",
    "            node_id += 1\n",
    "    return node_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1152, 1153, 1154, 1149, 1150, 1151}\n"
     ]
    }
   ],
   "source": [
    "# 按照日期升序排列\n",
    "edges_df = edges_df.sort_values(by=['date_id'],ascending=[True])\n",
    "node_id_maps=load_data(node_id_file)\n",
    "# 按照日期成组\n",
    "graph_edges_dfs = edges_df.groupby(by=\"date_id\")\n",
    "for graph_id,graph_edges_df in enumerate(graph_edges_dfs):\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    node_id_maps[graph_id] = add_single_graph_node_map(graph_edges_df[1],node_id_map)\n",
    "node_nums = set()\n",
    "for node_id_map in node_id_maps:\n",
    "    node_nums.add(len(node_id_map))\n",
    "print(node_nums)\n",
    "save_data(node_id_maps,node_id_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 获取每个图的结点数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_num_nodes(output_file,node_id_maps):\n",
    "    graphs_row = []\n",
    "    for graph_id, node_id_map in enumerate(node_id_maps):\n",
    "        print(f\"graph {graph_id} num_nodes is {len(node_id_map)}\")\n",
    "        graph_row = [graph_id,len(node_id_map)]\n",
    "        graphs_row.append(graph_row)\n",
    "    df = pd.DataFrame(graphs_row,columns=['graph_id','num_nodes']) \n",
    "    df.to_csv(output_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph 0 num_nodes is 1152\n",
      "graph 1 num_nodes is 1150\n",
      "graph 2 num_nodes is 1152\n",
      "graph 3 num_nodes is 1152\n",
      "graph 4 num_nodes is 1151\n",
      "graph 5 num_nodes is 1152\n",
      "graph 6 num_nodes is 1151\n",
      "graph 7 num_nodes is 1153\n",
      "graph 8 num_nodes is 1152\n",
      "graph 9 num_nodes is 1151\n",
      "graph 10 num_nodes is 1152\n",
      "graph 11 num_nodes is 1151\n",
      "graph 12 num_nodes is 1151\n",
      "graph 13 num_nodes is 1151\n",
      "graph 14 num_nodes is 1151\n",
      "graph 15 num_nodes is 1151\n",
      "graph 16 num_nodes is 1151\n",
      "graph 17 num_nodes is 1151\n",
      "graph 18 num_nodes is 1152\n",
      "graph 19 num_nodes is 1150\n",
      "graph 20 num_nodes is 1151\n",
      "graph 21 num_nodes is 1152\n",
      "graph 22 num_nodes is 1151\n",
      "graph 23 num_nodes is 1152\n",
      "graph 24 num_nodes is 1152\n",
      "graph 25 num_nodes is 1151\n",
      "graph 26 num_nodes is 1152\n",
      "graph 27 num_nodes is 1153\n",
      "graph 28 num_nodes is 1151\n",
      "graph 29 num_nodes is 1151\n",
      "graph 30 num_nodes is 1150\n",
      "graph 31 num_nodes is 1150\n",
      "graph 32 num_nodes is 1151\n",
      "graph 33 num_nodes is 1150\n",
      "graph 34 num_nodes is 1152\n",
      "graph 35 num_nodes is 1151\n",
      "graph 36 num_nodes is 1151\n",
      "graph 37 num_nodes is 1151\n",
      "graph 38 num_nodes is 1151\n",
      "graph 39 num_nodes is 1151\n",
      "graph 40 num_nodes is 1149\n",
      "graph 41 num_nodes is 1151\n",
      "graph 42 num_nodes is 1149\n",
      "graph 43 num_nodes is 1149\n",
      "graph 44 num_nodes is 1150\n",
      "graph 45 num_nodes is 1152\n",
      "graph 46 num_nodes is 1151\n",
      "graph 47 num_nodes is 1150\n",
      "graph 48 num_nodes is 1150\n",
      "graph 49 num_nodes is 1150\n",
      "graph 50 num_nodes is 1149\n",
      "graph 51 num_nodes is 1149\n",
      "graph 52 num_nodes is 1150\n",
      "graph 53 num_nodes is 1149\n",
      "graph 54 num_nodes is 1151\n",
      "graph 55 num_nodes is 1149\n",
      "graph 56 num_nodes is 1150\n",
      "graph 57 num_nodes is 1149\n",
      "graph 58 num_nodes is 1150\n",
      "graph 59 num_nodes is 1151\n",
      "graph 60 num_nodes is 1151\n",
      "graph 61 num_nodes is 1150\n",
      "graph 62 num_nodes is 1151\n",
      "graph 63 num_nodes is 1151\n",
      "graph 64 num_nodes is 1151\n",
      "graph 65 num_nodes is 1153\n",
      "graph 66 num_nodes is 1151\n",
      "graph 67 num_nodes is 1152\n",
      "graph 68 num_nodes is 1151\n",
      "graph 69 num_nodes is 1152\n",
      "graph 70 num_nodes is 1152\n",
      "graph 71 num_nodes is 1151\n",
      "graph 72 num_nodes is 1153\n",
      "graph 73 num_nodes is 1152\n",
      "graph 74 num_nodes is 1152\n",
      "graph 75 num_nodes is 1154\n",
      "graph 76 num_nodes is 1153\n",
      "graph 77 num_nodes is 1153\n",
      "graph 78 num_nodes is 1153\n",
      "graph 79 num_nodes is 1153\n",
      "graph 80 num_nodes is 1152\n",
      "graph 81 num_nodes is 1153\n",
      "graph 82 num_nodes is 1154\n",
      "graph 83 num_nodes is 1154\n",
      "graph 84 num_nodes is 1153\n",
      "graph 85 num_nodes is 1154\n",
      "graph 86 num_nodes is 1153\n",
      "graph 87 num_nodes is 1153\n",
      "graph 88 num_nodes is 1153\n",
      "graph 89 num_nodes is 1154\n"
     ]
    }
   ],
   "source": [
    "save_graph_num_nodes(graph_propertity_file,node_id_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 新增src,dst,graph_id,node_id列数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增graph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df['graph_id'] = nodes_df['date_id'].map(graph_id_map)\n",
    "edges_df['graph_id'] = edges_df['date_id'].map(graph_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102597       0\n",
      "101845       1\n",
      "101844       2\n",
      "101843       3\n",
      "101842       4\n",
      "          ... \n",
      "760       1133\n",
      "761       1134\n",
      "762       1135\n",
      "756       1136\n",
      "0         1137\n",
      "Name: node_id, Length: 102598, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 需要依据graph_id 分组映射\n",
    "node_id_maps=load_data(\"../data/node_id_maps.pkl\")\n",
    "\n",
    "nodes_groupby_graph_id_df = nodes_df.groupby(by=\"graph_id\")\n",
    "result = []\n",
    "for graph_id,nodes_groupby_df in nodes_groupby_graph_id_df:\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    nodes_groupby_df['node_id'] = nodes_groupby_df['geohash_id'].map(node_id_map)\n",
    "    result.append(nodes_groupby_df)\n",
    "result = pd.concat(result)\n",
    "print(result[\"node_id\"])\n",
    "result.to_csv(output_node_file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增src，dst的node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938659     505\n",
      "220256     876\n",
      "986582     818\n",
      "633506     348\n",
      "895172     340\n",
      "          ... \n",
      "848215     480\n",
      "650400     883\n",
      "23587     1048\n",
      "168142     536\n",
      "246317     404\n",
      "Name: src, Length: 1048575, dtype: int64\n",
      "938659     923\n",
      "220256    1049\n",
      "986582     619\n",
      "633506     434\n",
      "895172     467\n",
      "          ... \n",
      "848215     791\n",
      "650400     825\n",
      "23587      601\n",
      "168142     864\n",
      "246317     828\n",
      "Name: dst, Length: 1048575, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 需要依据graph_id 分组映射\n",
    "node_id_maps=load_data(\"../data/node_id_maps.pkl\")\n",
    "\n",
    "edges_groupby_graph_id_df = edges_df.groupby(by=\"graph_id\")\n",
    "result = []\n",
    "for graph_id,edges_groupby_df in edges_groupby_graph_id_df:\n",
    "    node_id_map = node_id_maps[graph_id]\n",
    "    edges_groupby_df['src'] = edges_groupby_df['geohash6_point1'].map(node_id_map)\n",
    "    edges_groupby_df['dst'] = edges_groupby_df['geohash6_point2'].map(node_id_map)\n",
    "    result.append(edges_groupby_df)\n",
    "result = pd.concat(result)\n",
    "print(result[\"src\"])\n",
    "print(result[\"dst\"])\n",
    "result.to_csv(output_edge_file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
